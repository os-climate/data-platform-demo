{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee377720",
   "metadata": {},
   "source": [
    "# Ingest data in Trino\n",
    "This notebook shows how to ingest raw data in Trino. The data can then be used in Superset for visualization. First, we take raw csv files from a s3 bucket, create parquet files and then create tables in Trino that read from the parquet files. The notebook also shows how to join two tables on Trino to create a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "777a3c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pathlib\n",
    "import boto3\n",
    "import trino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b770d6d1",
   "metadata": {},
   "source": [
    "### Example `credentials.env` file\n",
    "\\# This file is required to connect with Trino and S3.\n",
    "\n",
    "```\n",
    "# s3 credentials\n",
    "S3_ENDPOINT=https://s3.us-east-1.amazonaws.com\n",
    "S3_BUCKET=ocp-odh-os-demo-s3\n",
    "S3_ACCESS_KEY=xxx\n",
    "S3_SECRET_KEY=xxx\n",
    "\n",
    "# trino credentials\n",
    "TRINO_USER=xxx\n",
    "TRINO_PASSWD=xxx\n",
    "TRINO_HOST=trino-secure-odh-trino.apps.odh-cl1.apps.os-climate.org\n",
    "TRINO_PORT=443\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e06c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load credentials\n",
    "dotenv_dir = os.environ.get(\n",
    "    \"CREDENTIAL_DOTENV_DIR\", os.environ.get(\"PWD\", \"/opt/app-root/src\")\n",
    ")\n",
    "dotenv_path = pathlib.Path(dotenv_dir) / \"credentials.env\"\n",
    "if os.path.exists(dotenv_path):\n",
    "    load_dotenv(dotenv_path=dotenv_path, override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82324fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an S3 client\n",
    "s3 = boto3.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=os.environ[\"S3_ENDPOINT\"],\n",
    "    aws_access_key_id=os.environ[\"S3_ACCESS_KEY\"],\n",
    "    aws_secret_access_key=os.environ[\"S3_SECRET_KEY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff563672",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.get_object(\n",
    "    Bucket=os.environ[\"S3_BUCKET\"],\n",
    "    Key=\"urgentem/UrgentemDataSampleEmissionsTargetsDec2020.csv\",\n",
    ")\n",
    "\n",
    "# load the raw file from the bucket\n",
    "df_emissions = (pd.read_csv(obj[\"Body\"])).convert_dtypes()\n",
    "\n",
    "# convert columns to specific data types\n",
    "df_emissions = df_emissions.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e29158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_2 = s3.get_object(\n",
    "    Bucket=os.environ[\"S3_BUCKET\"], Key=\"urgentem/UrgentemDataSampleDec2020.csv\"\n",
    ")\n",
    "\n",
    "# load the raw file from the bucket\n",
    "df_emissions_2 = (pd.read_csv(obj_2[\"Body\"])).convert_dtypes()\n",
    "\n",
    "# convert columns to specific data types\n",
    "df_emissions_2 = df_emissions_2.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b777e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Methods to clean column names\n",
    "\n",
    "_wsdedup = re.compile(r\"\\s+\")\n",
    "_usdedup = re.compile(r\"__+\")\n",
    "_rmpunc = re.compile(r\"[,.()&$/+-]+\")\n",
    "_p2smap = {\"string\": \"varchar\", \"Float64\": \"double\", \"Int64\": \"bigint\"}\n",
    "\n",
    "\n",
    "def snakify(name, maxlen):\n",
    "    w = name.casefold().rstrip().lstrip()\n",
    "    w = w.replace(\"-\", \"_\")\n",
    "    w = _rmpunc.sub(\"\", w)\n",
    "    w = _wsdedup.sub(\"_\", w)\n",
    "    w = _usdedup.sub(\"_\", w)\n",
    "    w = w.replace(\"average\", \"avg\")\n",
    "    w = w.replace(\"maximum\", \"max\")\n",
    "    w = w.replace(\"minimum\", \"min\")\n",
    "    w = w.replace(\"absolute\", \"abs\")\n",
    "    w = w.replace(\"source\", \"src\")\n",
    "    w = w.replace(\"distribution\", \"dist\")\n",
    "    # these are common in the sample names but unsure of standard abbv\n",
    "    # w = w.replace(\"inference\", \"inf\")\n",
    "    # w = w.replace(\"emissions\", \"emis\")\n",
    "    # w = w.replace(\"intensity\", \"int\")\n",
    "    # w = w.replace(\"reported\", \"rep\")\n",
    "    # w = w.replace(\"revenue\", \"rev\")\n",
    "    w = w[:maxlen]\n",
    "    return w\n",
    "\n",
    "\n",
    "def snakify_columns(df, inplace=False, maxlen=63):\n",
    "    icols = df.columns.to_list()\n",
    "    ocols = [snakify(e, maxlen=maxlen) for e in icols]\n",
    "    if len(set(ocols)) < len(ocols):\n",
    "        raise ValueError(\"remapped column names were not unique!\")\n",
    "    rename_map = dict(list(zip(icols, ocols)))\n",
    "    return df.rename(columns=rename_map, inplace=inplace)\n",
    "\n",
    "\n",
    "def pandas_type_to_sql(pt):\n",
    "    st = _p2smap.get(pt)\n",
    "    if st is not None:\n",
    "        return st\n",
    "    raise ValueError(\"unexpected pandas column type '{pt}'\".format(pt=pt))\n",
    "\n",
    "\n",
    "# add ability to specify optional dict for specific fields?\n",
    "# if column name is present, use specified value?\n",
    "def generate_table_schema_pairs(df):\n",
    "    ptypes = [str(e) for e in df.dtypes.to_list()]\n",
    "    stypes = [pandas_type_to_sql(e) for e in ptypes]\n",
    "    pz = list(zip(df.columns.to_list(), stypes))\n",
    "    return \",\\n\".join([\"    {n} {t}\".format(n=e[0], t=e[1]) for e in pz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "144e3525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map column names to a form that works for SQL\n",
    "snakify_columns(df_emissions, inplace=True)\n",
    "\n",
    "# map column names to a form that works for SQL\n",
    "# Had to increase the snakify max length to 100 to avoid column name repetition\n",
    "snakify_columns(df_emissions_2, inplace=True, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da9dbd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19 entries, 0 to 18\n",
      "Data columns (total 15 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   company_name                        19 non-null     string \n",
      " 1   isin                                19 non-null     string \n",
      " 2   target_type                         19 non-null     string \n",
      " 3   scope                               19 non-null     string \n",
      " 4   coverage_s1                         16 non-null     Float64\n",
      " 5   coverage_s2                         15 non-null     Float64\n",
      " 6   coverage_s3                         4 non-null      Int64  \n",
      " 7   reduction_ambition                  19 non-null     Float64\n",
      " 8   base_year                           19 non-null     Int64  \n",
      " 9   end_year                            19 non-null     Int64  \n",
      " 10  start_year                          19 non-null     Int64  \n",
      " 11  base_year_ghg_emissions_s1_tco2e    1 non-null      string \n",
      " 12  base_year_ghg_emissions_s1s2_tco2e  14 non-null     string \n",
      " 13  base_year_ghg_emissions_s3_tco2e    18 non-null     string \n",
      " 14  achieved_reduction                  19 non-null     Float64\n",
      "dtypes: Float64(4), Int64(4), string(7)\n",
      "memory usage: 2.5 KB\n"
     ]
    }
   ],
   "source": [
    "# a way to examine the structure of a pandas data frame\n",
    "df_emissions.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6890c",
   "metadata": {},
   "source": [
    "# Save parquet files for Trino tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2178530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet has multiple options for appending or updating data\n",
    "# including adding new files, or appending, sharding directory trees, etc\n",
    "df_emissions.to_parquet(\"/tmp/emissions_table1.parquet\", index=False)\n",
    "s3.upload_file(\n",
    "    Bucket=os.environ[\"S3_BUCKET\"],\n",
    "    Key=\"urgentem/trino/itr_emissions_join_1/emissions.parquet\",\n",
    "    Filename=\"/tmp/emissions_table1.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b98c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parquet has multiple options for appending or updating data\n",
    "# including adding new files, or appending, sharding directory trees, etc\n",
    "df_emissions_2.to_parquet(\"/tmp/emissions_table2.parquet\", index=False)\n",
    "s3.upload_file(\n",
    "    Bucket=os.environ[\"S3_BUCKET\"],\n",
    "    Key=\"urgentem/trino/itr_emissions_join_2/emissions.parquet\",\n",
    "    Filename=\"/tmp/emissions_table2.parquet\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4fffc",
   "metadata": {},
   "source": [
    "# Interaction with Trino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb9b7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = trino.dbapi.connect(\n",
    "    auth=trino.auth.BasicAuthentication(\n",
    "        os.environ[\"TRINO_USER\"], os.environ[\"TRINO_PASSWD\"]\n",
    "    ),\n",
    "    host=os.environ[\"TRINO_HOST\"],\n",
    "    port=int(os.environ[\"TRINO_PORT\"]),\n",
    "    http_scheme=\"https\",\n",
    "    verify=True,\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7ab32e",
   "metadata": {},
   "source": [
    "## Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d0b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create table if not exists default.urgentem.itr_emissions_1(\n",
      "    company_name varchar,\n",
      "    isin varchar,\n",
      "    target_type varchar,\n",
      "    scope varchar,\n",
      "    coverage_s1 double,\n",
      "    coverage_s2 double,\n",
      "    coverage_s3 bigint,\n",
      "    reduction_ambition double,\n",
      "    base_year bigint,\n",
      "    end_year bigint,\n",
      "    start_year bigint,\n",
      "    base_year_ghg_emissions_s1_tco2e varchar,\n",
      "    base_year_ghg_emissions_s1s2_tco2e varchar,\n",
      "    base_year_ghg_emissions_s3_tco2e varchar,\n",
      "    achieved_reduction double\n",
      ") with (\n",
      "    format = 'parquet',\n",
      "    external_location = 's3a://ocp-odh-os-demo-s3/urgentem/trino/itr_emissions_join_1/'\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a sql schema that will correspond to the data types\n",
    "# of columns in the pandas DF\n",
    "# to-do: add some mechanisms for overriding types, either here\n",
    "# or on the pandas data-frame itself before we write it out\n",
    "schema = generate_table_schema_pairs(df_emissions)\n",
    "\n",
    "tabledef = \"\"\"create table if not exists default.urgentem.itr_emissions_1(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://ocp-odh-os-demo-s3/urgentem/trino/itr_emissions_join_1/'\n",
    ")\"\"\".format(\n",
    "    schema=schema\n",
    ")\n",
    "print(tabledef)\n",
    "\n",
    "# tables created externally may not show up immediately in cloud-beaver\n",
    "cur.execute(tabledef)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef7c4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create table if not exists default.urgentem.itr_emissions_2(\n",
      "    company_short_name varchar,\n",
      "    isin varchar,\n",
      "    sedol varchar,\n",
      "    bloomberg_ticker varchar,\n",
      "    urgentem_disclosure_category bigint,\n",
      "    number_of_scope_3_categories_disclosed bigint,\n",
      "    country varchar,\n",
      "    region varchar,\n",
      "    intensity_avg_inference_scope_1_2_3_total_tco2em_revenue double,\n",
      "    intensity_avg_inference_scope_1_2_total_tco2em_revenue double,\n",
      "    intensity_avg_inference_scope_1_2_total_tco2em_revenue_src varchar,\n",
      "    intensity_avg_inference_scope_3_total_tco2em_revenue double,\n",
      "    intensity_avg_inference_scope_3_total_tco2em_revenue_src varchar,\n",
      "    intensity_avg_inference_scope_1_tco2em_revenue double,\n",
      "    intensity_avg_inference_scope_1_tco2em_revenue_src varchar,\n",
      "    intensity_avg_inference_scope_2_location_based_tco2em_revenue double,\n",
      "    intensity_avg_inference_scope_2_location_based_tco2em_revenue_src varchar,\n",
      "    intensity_avg_inference_scope_2_market_based_tco2em_revenue double,\n",
      "    intensity_av\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[True]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1  # generate a sql schema that will correspond to the data types\n",
    "# of columns in the pandas DF\n",
    "# to-do: add some mechanisms for overriding types, either here\n",
    "# or on the pandas data-frame itself before we write it out\n",
    "schema = generate_table_schema_pairs(df_emissions_2)\n",
    "\n",
    "tabledef = \"\"\"create table if not exists default.urgentem.itr_emissions_2(\n",
    "{schema}\n",
    ") with (\n",
    "    format = 'parquet',\n",
    "    external_location = 's3a://ocp-odh-os-demo-s3/urgentem/trino/itr_emissions_join_2/'\n",
    ")\"\"\".format(\n",
    "    schema=schema\n",
    ")\n",
    "print(tabledef[:1000])\n",
    "\n",
    "# tables created externally may not show up immediately in cloud-beaver\n",
    "cur.execute(tabledef)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "484af7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADIDAS AG',\n",
       " 'DE000A1EWWW0',\n",
       " 'Absolute',\n",
       " 'S1+S2',\n",
       " 0.9,\n",
       " 0.9,\n",
       " None,\n",
       " 0.15,\n",
       " 2015,\n",
       " 2020,\n",
       " 2015,\n",
       " None,\n",
       " ' 59,132 ',\n",
       " ' 295,660 ',\n",
       " 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if table 1 is there\n",
    "cur.execute(\"select * from default.urgentem.itr_emissions_1 LIMIT 5\")\n",
    "cur.fetchall()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21bb00cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADIDAS AG',\n",
       " 'DE000A1EWWW0',\n",
       " '4031976',\n",
       " 'ADS GR',\n",
       " 3,\n",
       " 3,\n",
       " 'Germany',\n",
       " 'Europe',\n",
       " 301.0,\n",
       " 17.5,\n",
       " 'Sum of Location and Scope One',\n",
       " 283.5,\n",
       " 'Sum of Average Category Intensities',\n",
       " 1.8,\n",
       " 'Inferred - Average - Industry winsor']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check if table 2 is there\n",
    "cur.execute(\"select * from default.urgentem.itr_emissions_2 LIMIT 5\")\n",
    "cur.fetchall()[1][:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc6aadd",
   "metadata": {},
   "source": [
    "# Join the two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20fa5e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate column names for df_emissions table\n",
    "# removing isin column to avoid duplication\n",
    "# of key column in the join operation\n",
    "b_columns = list(df_emissions.columns)\n",
    "b_columns.remove(\"isin\")\n",
    "b_columns = [\"default.urgentem.itr_emissions_1.\" + i for i in b_columns]\n",
    "b_columns = \", \".join(b_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0015a265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE if not exists default.urgentem.itr_emissions_joined_2 AS              SELECT default.urgentem.itr_emissions_2.*, default.urgentem.itr_emissions_1.company_name, default.urgentem.itr_emissions_1.target_type, default.urgentem.itr_emissions_1.scope, default.urgentem.itr_emissions_1.coverage_s1, default.urgentem.itr_emissions_1.coverage_s2, default.urgentem.itr_emissions_1.coverage_s3, default.urgentem.itr_emissions_1.reduction_ambition, default.urgentem.itr_emissions_1.base_year, default.urgentem.itr_emissions_1.end_year, default.urgentem.itr_emissions_1.start_year, default.urgentem.itr_emissions_1.base_year_ghg_emissions_s1_tco2e, default.urgentem.itr_emissions_1.base_year_ghg_emissions_s1s2_tco2e, default.urgentem.itr_emissions_1.base_year_ghg_emissions_s3_tco2e, default.urgentem.itr_emissions_1.achieved_reduction               FROM default.urgentem.itr_emissions_2               LEFT JOIN default.urgentem.itr_emissions_1               ON default.urgentem.itr_emissions_1.isin=default.urgentem.itr_emissions_2.isin'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write the join_query\n",
    "join_query = f\"CREATE TABLE if not exists default.urgentem.itr_emissions_joined_2 AS\\\n",
    "              SELECT default.urgentem.itr_emissions_2.*, {b_columns} \\\n",
    "              FROM default.urgentem.itr_emissions_2 \\\n",
    "              LEFT JOIN default.urgentem.itr_emissions_1 \\\n",
    "              ON default.urgentem.itr_emissions_1.isin=default.urgentem.itr_emissions_2.isin\"\n",
    "join_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dae3ca01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(join_query)\n",
    "cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00f9f3af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>176</th>\n",
       "      <th>177</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHRISTIAN DIOR</td>\n",
       "      <td>FR0000130403</td>\n",
       "      <td>4061393</td>\n",
       "      <td>CDI FP</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>France</td>\n",
       "      <td>Europe</td>\n",
       "      <td>167.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EQUINOR ASA</td>\n",
       "      <td>NO0010096985</td>\n",
       "      <td>7133608</td>\n",
       "      <td>EQNR NO</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Europe</td>\n",
       "      <td>5361.8</td>\n",
       "      <td>262.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9,329,201</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLAXOSMITHKLINE</td>\n",
       "      <td>GB0009252882</td>\n",
       "      <td>925288</td>\n",
       "      <td>GSK LN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>485.4</td>\n",
       "      <td>33.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2030.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7,475,825</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLAXOSMITHKLINE</td>\n",
       "      <td>GB0009252882</td>\n",
       "      <td>925288</td>\n",
       "      <td>GSK LN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Europe</td>\n",
       "      <td>485.4</td>\n",
       "      <td>33.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1,495,165</td>\n",
       "      <td>7,475,825</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IBERDROLA SA</td>\n",
       "      <td>ES0144580Y14</td>\n",
       "      <td>B288C92</td>\n",
       "      <td>IBE SM</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Europe</td>\n",
       "      <td>1753.6</td>\n",
       "      <td>665.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1        2        3    4    5               6    \\\n",
       "0   CHRISTIAN DIOR  FR0000130403  4061393   CDI FP    1    3          France   \n",
       "1      EQUINOR ASA  NO0010096985  7133608  EQNR NO    1   13          Norway   \n",
       "2  GLAXOSMITHKLINE  GB0009252882   925288   GSK LN    1   12  United Kingdom   \n",
       "3  GLAXOSMITHKLINE  GB0009252882   925288   GSK LN    1   12  United Kingdom   \n",
       "4     IBERDROLA SA  ES0144580Y14  B288C92   IBE SM    1    5           Spain   \n",
       "\n",
       "      7       8      9    ...  176  177   178     179     180     181  \\\n",
       "0  Europe   167.1    5.3  ...  NaN  NaN   NaN     NaN     NaN     NaN   \n",
       "1  Europe  5361.8  262.1  ...  NaN  NaN  0.21  2016.0  2030.0  2017.0   \n",
       "2  Europe   485.4   33.9  ...  NaN  1.0  0.16  2017.0  2030.0  2017.0   \n",
       "3  Europe   485.4   33.9  ...  1.0  NaN  1.00  2017.0  2025.0  2017.0   \n",
       "4  Europe  1753.6  665.5  ...  NaN  NaN   NaN     NaN     NaN     NaN   \n",
       "\n",
       "           182          183          184   185  \n",
       "0         None         None         None   NaN  \n",
       "1   9,329,201          None         None  0.06  \n",
       "2         None         None   7,475,825   0.00  \n",
       "3         None   1,495,165    7,475,825   0.88  \n",
       "4         None         None         None   NaN  \n",
       "\n",
       "[5 rows x 186 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"select * from default.urgentem.itr_emissions_joined_2 LIMIT 5\")\n",
    "pd.DataFrame(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbb780f",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We saw how to take a raw csv file on s3 and convert it to parquet format. We also used the trino api to create tables from parquet files as well as from join operation on existing tables. The tables can now be used in a Superset dashboard for visualization. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
